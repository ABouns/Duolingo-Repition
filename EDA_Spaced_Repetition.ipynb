{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class CFG:\n",
    "    data_path: Path = Path(\"Datathon/DATA/Spaced Repetition Data\")\n",
    "    figure_dpi: int = 150\n",
    "    k_range_iter: range = range(2, 11)\n",
    "    random_state: int = 42\n",
    "    gbtm_max_patients: int = 200_000\n",
    "    kproto_max_patients: int = 150_000\n",
    "    ssa_max_patients: int = 150_000\n",
    "    preview_nrows: int = 500_000\n",
    "    max_rows_for_plots: int = 1_000_000\n",
    "    min_group_size: int = 30\n",
    "\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "np.random.seed(cfg.random_state)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: data_path=Datathon/DATA/Spaced Repetition Data\n",
      "  k_range=[2, 3, 4, 5, 6, 7, 8, 9, 10], random_state=42\n",
      "  gbtm_max=200,000, kproto_max=150,000, ssa_max=150,000\n"
     ]
    }
   ],
   "source": [
    "# \u2500\u2500 Anthropic-inspired warm theme \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": cfg.figure_dpi,\n",
    "    \"figure.facecolor\": \"#FDF8F4\",\n",
    "    \"axes.facecolor\": \"#FDF8F4\",\n",
    "    \"savefig.facecolor\": \"#FDF8F4\",\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Segoe UI\", \"Helvetica Neue\", \"Arial\", \"sans-serif\"],\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.left\": False,\n",
    "    \"axes.spines.bottom\": False,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.color\": \"#E8DDD4\",\n",
    "    \"grid.linewidth\": 0.8,\n",
    "    \"grid.alpha\": 0.7,\n",
    "    \"axes.labelcolor\": \"#8A7E74\",\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.titleweight\": \"600\",\n",
    "    \"axes.titlecolor\": \"#3D3229\",\n",
    "    \"xtick.color\": \"#8A7E74\",\n",
    "    \"ytick.color\": \"#8A7E74\",\n",
    "    \"xtick.major.size\": 0,\n",
    "    \"ytick.major.size\": 0,\n",
    "    \"text.color\": \"#3D3229\",\n",
    "    \"legend.frameon\": False,\n",
    "})\n",
    "\n",
    "print(f\"Config: data_path={cfg.data_path}\")\n",
    "print(f\"  k_range={list(cfg.k_range_iter)}, random_state={cfg.random_state}\")\n",
    "print(f\"  gbtm_max={cfg.gbtm_max_patients:,}, kproto_max={cfg.kproto_max_patients:,}, ssa_max={cfg.ssa_max_patients:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3701277545.py, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/2q/ghzbxc6x7lz2msm0m0blzx2c0000gn/T/ipykernel_59798/3701277545.py\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    print(f\"\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def resolve_data_target(path_like: Path) -> Path:\n",
    "    candidates = [\n",
    "        path_like,\n",
    "        Path.cwd() / path_like,\n",
    "        Path.home() / path_like,\n",
    "        Path.home() / \"Documents\" / path_like,\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not resolve data path '{path_like}'. Checked: \"\n",
    "        + \", \".join(str(c) for c in candidates)\n",
    "    )\n",
    "\n",
    "\n",
    "def list_data_files(target: Path) -> List[Path]:\n",
    "    if target.is_file():\n",
    "        return [target]\n",
    "    files = [p for p in sorted(target.iterdir()) if p.is_file() and not p.name.startswith(\".\")]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No readable files found in directory: {target}\")\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_table(path: Path) -> pd.DataFrame:\n",
    "    suffix = path.suffix.lower()\n",
    "    try:\n",
    "        if suffix == \".parquet\":\n",
    "            return pd.read_parquet(path)\n",
    "        if suffix == \".feather\":\n",
    "            return pd.read_feather(path)\n",
    "        if suffix in {\".pkl\", \".pickle\"}:\n",
    "            return pd.read_pickle(path)\n",
    "        if suffix in {\".xlsx\", \".xls\"}:\n",
    "            return pd.read_excel(path)\n",
    "        if suffix == \".json\":\n",
    "            try:\n",
    "                return pd.read_json(path, lines=True)\n",
    "            except ValueError:\n",
    "                return pd.read_json(path)\n",
    "        if suffix == \".tsv\":\n",
    "            return pd.read_csv(path, sep=\"\t\", low_memory=False)\n",
    "        if suffix == \".txt\":\n",
    "            return pd.read_csv(path, sep=None, engine=\"python\", low_memory=False)\n",
    "        return pd.read_csv(path, low_memory=False)\n",
    "    except MemoryError:\n",
    "        print(f\"MemoryError for {path.name}. Falling back to first {cfg.preview_nrows:,} rows.\")\n",
    "        if suffix == \".tsv\":\n",
    "            return pd.read_csv(path, sep=\"\t\", low_memory=False, nrows=cfg.preview_nrows)\n",
    "        if suffix == \".txt\":\n",
    "            return pd.read_csv(path, sep=None, engine=\"python\", low_memory=False, nrows=cfg.preview_nrows)\n",
    "        return pd.read_csv(path, low_memory=False, nrows=cfg.preview_nrows)\n",
    "\n",
    "\n",
    "data_target = resolve_data_target(cfg.data_path)\n",
    "file_paths = list_data_files(data_target)\n",
    "\n",
    "print(f\"Resolved data target: {data_target}\")\n",
    "print(f\"Files discovered: {len(file_paths)}\")\n",
    "\n",
    "tables: Dict[str, pd.DataFrame] = {}\n",
    "for fp in file_paths:\n",
    "    table_name = fp.stem if fp.stem else fp.name\n",
    "    print(f\"\\nLoading: {fp.name}\")\n",
    "    df_loaded = load_table(fp)\n",
    "    tables[table_name] = df_loaded\n",
    "\n",
    "    print(f\"Shape: {df_loaded.shape}\")\n",
    "    print(\"Columns and dtypes:\")\n",
    "    display(pd.DataFrame({\"column\": df_loaded.columns, \"dtype\": df_loaded.dtypes.astype(str)}))\n",
    "\n",
    "    print(\"First 5 rows:\")\n",
    "    display(df_loaded.head(5))\n",
    "\n",
    "dataset_shapes = {name: frame.shape for name, frame in tables.items()}\n",
    "print(\"\\nDataset shapes summary:\")\n",
    "for name, shape in dataset_shapes.items():\n",
    "    print(f\"- {name}: {shape}\")\n",
    "\n",
    "primary_table_name = max(tables.keys(), key=lambda k: len(tables[k]))\n",
    "df = tables[primary_table_name].copy()\n",
    "print(f\"\\nPrimary analysis table: {primary_table_name} ({df.shape[0]:,} rows, {df.shape[1]} columns)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Scope\n",
    "This notebook performs a reproducible, event-level exploratory analysis of spaced repetition behavior. It includes data quality checks, distributional diagnostics, temporal dynamics, user/item heterogeneity, and interaction analyses aligned with thesis-grade reporting.\n",
    "\n",
    "The largest loaded table is treated as the primary event log (`df`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_column(columns: pd.Index, patterns: List[str], blocked: Optional[Set[str]] = None) -> Optional[str]:\n",
    "    blocked = blocked or set()\n",
    "    for col in columns:\n",
    "        if col in blocked:\n",
    "            continue\n",
    "        low = col.lower()\n",
    "        if any(re.search(pat, low) for pat in patterns):\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "\n",
    "schema = {\n",
    "    \"user_col\": \"user_id\" if \"user_id\" in df.columns else infer_column(df.columns, [r\"user\", r\"student\", r\"learner\", r\"uid\"]),\n",
    "    \"item_col\": \"lexeme_id\" if \"lexeme_id\" in df.columns else infer_column(df.columns, [r\"lexeme\", r\"item\", r\"card\", r\"question\", r\"token\"]),\n",
    "    \"time_col\": \"timestamp\" if \"timestamp\" in df.columns else infer_column(df.columns, [r\"timestamp\", r\"time\", r\"date\", r\"datetime\", r\"ts\"]),\n",
    "    \"prob_col\": \"p_recall\" if \"p_recall\" in df.columns else infer_column(df.columns, [r\"recall\", r\"outcome\", r\"success\", r\"accuracy\", r\"correct\"]),\n",
    "    \"interval_col\": \"delta\" if \"delta\" in df.columns else infer_column(df.columns, [r\"delta\", r\"interval\", r\"lag\", r\"elapsed\"]),\n",
    "    \"learn_lang_col\": \"learning_language\" if \"learning_language\" in df.columns else infer_column(df.columns, [r\"learning_language\", r\"learn.*lang\", r\"target.*lang\", r\"language\"]),\n",
    "    \"ui_lang_col\": \"ui_language\" if \"ui_language\" in df.columns else infer_column(df.columns, [r\"ui_language\", r\"interface.*lang\", r\"ui.*lang\"]),\n",
    "}\n",
    "\n",
    "\n",
    "def parse_event_time(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        parsed = pd.to_datetime(series, errors=\"coerce\", utc=True)\n",
    "        return parsed.dt.tz_convert(None)\n",
    "\n",
    "    as_num = pd.to_numeric(series, errors=\"coerce\")\n",
    "    if as_num.notna().mean() > 0.80:\n",
    "        median_value = as_num.dropna().median()\n",
    "        if median_value > 1e14:\n",
    "            unit = \"ns\"\n",
    "        elif median_value > 1e11:\n",
    "            unit = \"ms\"\n",
    "        else:\n",
    "            unit = \"s\"\n",
    "        parsed = pd.to_datetime(as_num, unit=unit, errors=\"coerce\", utc=True)\n",
    "        return parsed.dt.tz_convert(None)\n",
    "\n",
    "    parsed = pd.to_datetime(series, errors=\"coerce\", utc=True)\n",
    "    return parsed.dt.tz_convert(None)\n",
    "\n",
    "\n",
    "if schema[\"time_col\"] is not None:\n",
    "    df[\"_event_time\"] = parse_event_time(df[schema[\"time_col\"]])\n",
    "    df[\"_event_date\"] = df[\"_event_time\"].dt.date\n",
    "    df[\"_event_hour\"] = df[\"_event_time\"].dt.hour\n",
    "    df[\"_event_dow\"] = df[\"_event_time\"].dt.day_name()\n",
    "\n",
    "if {\"history_correct\", \"history_seen\"}.issubset(df.columns):\n",
    "    denom = pd.to_numeric(df[\"history_seen\"], errors=\"coerce\").replace(0, np.nan)\n",
    "    numer = pd.to_numeric(df[\"history_correct\"], errors=\"coerce\")\n",
    "    df[\"history_acc\"] = numer / denom\n",
    "\n",
    "if {\"session_correct\", \"session_seen\"}.issubset(df.columns):\n",
    "    denom = pd.to_numeric(df[\"session_seen\"], errors=\"coerce\").replace(0, np.nan)\n",
    "    numer = pd.to_numeric(df[\"session_correct\"], errors=\"coerce\")\n",
    "    df[\"session_acc\"] = numer / denom\n",
    "\n",
    "if schema[\"interval_col\"] is not None:\n",
    "    interval_num = pd.to_numeric(df[schema[\"interval_col\"]], errors=\"coerce\")\n",
    "    df[\"log_interval\"] = np.log1p(interval_num.clip(lower=0))\n",
    "\n",
    "schema_overview = pd.DataFrame({\"role\": list(schema.keys()), \"column\": list(schema.values())})\n",
    "print(\"Inferred schema:\")\n",
    "display(schema_overview)\n",
    "\n",
    "memory_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"Working table memory footprint: {memory_mb:,.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Analysis\n",
    "Missingness is profiled both in counts and percentages to identify potential non-random gaps that can bias downstream trajectory, clustering, or survival-style analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = df.isna().sum()\n",
    "missing_pct = (missing_count / len(df) * 100).round(3)\n",
    "missing_table = (\n",
    "    pd.DataFrame({\"missing_n\": missing_count, \"missing_pct\": missing_pct})\n",
    "    .sort_values([\"missing_n\", \"missing_pct\"], ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Top missingness columns:\")\n",
    "display(missing_table.head(25))\n",
    "\n",
    "missing_nonzero = missing_table[missing_table[\"missing_n\"] > 0].head(20)\n",
    "if not missing_nonzero.empty:\n",
    "    plt.figure(figsize=(10, max(4, 0.35 * len(missing_nonzero))))\n",
    "    sns.barplot(\n",
    "        data=missing_nonzero.reset_index(),\n",
    "        x=\"missing_pct\",\n",
    "        y=\"index\",\n",
    "        color=\"#C17C3A\",\n",
    "    )\n",
    "    plt.title(\"Missingness Rate by Column\")\n",
    "    plt.xlabel(\"Missing (%)\")\n",
    "    plt.ylabel(\"Column\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "Numeric and categorical summaries are reported with robust percentiles and cardinality diagnostics. This supports quick detection of skew, sparsity, and extreme values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "object_cols = df.select_dtypes(include=[\"object\", \"category\", \"string\"]).columns.tolist()\n",
    "\n",
    "if numeric_cols:\n",
    "    numeric_summary = df[numeric_cols].describe(\n",
    "        percentiles=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]\n",
    "    ).T\n",
    "    numeric_summary[\"iqr\"] = numeric_summary[\"75%\"] - numeric_summary[\"25%\"]\n",
    "    numeric_summary[\"cv\"] = numeric_summary[\"std\"] / numeric_summary[\"mean\"].replace(0, np.nan)\n",
    "    print(\"Numeric summary:\")\n",
    "    display(numeric_summary.sort_values(\"count\", ascending=False))\n",
    "\n",
    "if object_cols:\n",
    "    cat_rows = []\n",
    "    for col in object_cols:\n",
    "        vc = df[col].value_counts(dropna=True)\n",
    "        top_value = vc.index[0] if len(vc) else np.nan\n",
    "        top_freq = int(vc.iloc[0]) if len(vc) else 0\n",
    "        cat_rows.append(\n",
    "            {\n",
    "                \"column\": col,\n",
    "                \"n_unique\": int(df[col].nunique(dropna=True)),\n",
    "                \"missing_pct\": float(df[col].isna().mean() * 100),\n",
    "                \"top_value\": top_value,\n",
    "                \"top_freq\": top_freq,\n",
    "            }\n",
    "        )\n",
    "    cat_summary = pd.DataFrame(cat_rows).sort_values(\"n_unique\", ascending=False)\n",
    "    print(\"Categorical summary:\")\n",
    "    display(cat_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributional Diagnostics\n",
    "This section examines marginal distributions for key numerical variables and high-level category prevalence. Heavy tails are clipped at extreme quantiles for readability in plots while preserving the full-data summaries above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df\n",
    "if len(df) > cfg.max_rows_for_plots:\n",
    "    plot_df = df.sample(cfg.max_rows_for_plots, random_state=cfg.random_state)\n",
    "\n",
    "priority_numeric = [\n",
    "    \"p_recall\",\n",
    "    \"delta\",\n",
    "    \"history_seen\",\n",
    "    \"history_correct\",\n",
    "    \"session_seen\",\n",
    "    \"session_correct\",\n",
    "    \"history_acc\",\n",
    "    \"session_acc\",\n",
    "    \"log_interval\",\n",
    "]\n",
    "\n",
    "dist_cols = [c for c in priority_numeric if c in plot_df.columns]\n",
    "if len(dist_cols) < 8:\n",
    "    for c in numeric_cols:\n",
    "        if c not in dist_cols:\n",
    "            dist_cols.append(c)\n",
    "        if len(dist_cols) >= 8:\n",
    "            break\n",
    "\n",
    "if dist_cols:\n",
    "    n_plots = len(dist_cols)\n",
    "    n_cols = 2\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4 * n_rows))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for idx, col in enumerate(dist_cols):\n",
    "        ax = axes[idx]\n",
    "        s = pd.to_numeric(plot_df[col], errors=\"coerce\").dropna()\n",
    "        if s.empty:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "\n",
    "        if s.nunique() > 1:\n",
    "            lo, hi = s.quantile([0.01, 0.99])\n",
    "            s = s[(s >= lo) & (s <= hi)]\n",
    "\n",
    "        sns.histplot(s, bins=50, kde=True, ax=ax, color=\"#C17C3A\")\n",
    "        ax.set_title(f\"Distribution: {col}\")\n",
    "        ax.set_xlabel(col)\n",
    "\n",
    "    for idx in range(n_plots, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "cat_focus = [schema[\"learn_lang_col\"], schema[\"ui_lang_col\"]]\n",
    "cat_focus = [c for c in cat_focus if c is not None and c in df.columns]\n",
    "for col in cat_focus:\n",
    "    counts = df[col].value_counts(dropna=False).head(15).rename_axis(col).reset_index(name=\"count\")\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    sns.barplot(data=counts, x=col, y=\"count\", color=\"#AB6B2D\")\n",
    "    plt.title(f\"Top Categories: {col}\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Patterns\n",
    "Temporal analyses quantify review volume dynamics, circadian/weekly engagement structure, and (where available) response-quality drift over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"_event_time\" not in df.columns or df[\"_event_time\"].notna().sum() == 0:\n",
    "    print(\"No usable timestamp column was found for temporal analysis.\")\n",
    "else:\n",
    "    temporal_df = df.dropna(subset=[\"_event_time\"]).copy()\n",
    "\n",
    "    daily_counts = temporal_df.set_index(\"_event_time\").resample(\"D\").size().rename(\"n_reviews\")\n",
    "    daily_ma7 = daily_counts.rolling(7, min_periods=1).mean()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "    daily_counts.plot(ax=axes[0], color=\"#7E5A3C\", linewidth=1.2, alpha=0.85)\n",
    "    daily_ma7.plot(ax=axes[0], color=\"#C17C3A\", linewidth=2)\n",
    "    axes[0].set_title(\"Daily Review Volume (with 7-day Moving Average)\")\n",
    "    axes[0].set_ylabel(\"Reviews per day\")\n",
    "\n",
    "    if schema[\"prob_col\"] is not None and schema[\"prob_col\"] in temporal_df.columns:\n",
    "        quality = pd.to_numeric(temporal_df[schema[\"prob_col\"]], errors=\"coerce\")\n",
    "        daily_quality = quality.groupby(temporal_df[\"_event_time\"].dt.floor(\"D\")).mean()\n",
    "        daily_quality.plot(ax=axes[1], color=\"#A86A2B\", linewidth=1.5)\n",
    "        axes[1].set_title(f\"Daily Mean {schema['prob_col']}\")\n",
    "        axes[1].set_ylabel(\"Mean outcome\")\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, \"No outcome column available for temporal quality trend.\", ha=\"center\", va=\"center\")\n",
    "        axes[1].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    hourly_profile = temporal_df[\"_event_time\"].dt.hour.value_counts().sort_index()\n",
    "    dow_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    dow_hour = (\n",
    "        temporal_df.assign(_dow=temporal_df[\"_event_time\"].dt.day_name(), _hour=temporal_df[\"_event_time\"].dt.hour)\n",
    "        .groupby([\"_dow\", \"_hour\"], observed=True)\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reindex(dow_order)\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 4.8))\n",
    "    sns.barplot(x=hourly_profile.index, y=hourly_profile.values, ax=axes[0], color=\"#B67634\")\n",
    "    axes[0].set_title(\"Review Activity by Hour of Day\")\n",
    "    axes[0].set_xlabel(\"Hour\")\n",
    "    axes[0].set_ylabel(\"Number of reviews\")\n",
    "\n",
    "    sns.heatmap(np.log1p(dow_hour), cmap=\"YlOrBr\", ax=axes[1])\n",
    "    axes[1].set_title(\"Log Activity Heatmap: Day-of-Week x Hour\")\n",
    "    axes[1].set_xlabel(\"Hour\")\n",
    "    axes[1].set_ylabel(\"Day of week\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Level Behavior\n",
    "User heterogeneity is characterized through workload, temporal persistence, lexical breadth, and performance metrics. This is essential for modeling latent learner trajectories and stratifying interventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_col = schema[\"user_col\"]\n",
    "item_col = schema[\"item_col\"]\n",
    "prob_col = schema[\"prob_col\"]\n",
    "interval_col = schema[\"interval_col\"]\n",
    "\n",
    "if user_col is None or user_col not in df.columns:\n",
    "    print(\"No user identifier column detected; skipping user-level analysis.\")\n",
    "else:\n",
    "    grouped = df.groupby(user_col, dropna=False)\n",
    "    user_stats = pd.DataFrame({\"n_reviews\": grouped.size()})\n",
    "\n",
    "    if item_col is not None and item_col in df.columns:\n",
    "        user_stats[\"n_unique_items\"] = grouped[item_col].nunique()\n",
    "\n",
    "    if \"_event_time\" in df.columns:\n",
    "        user_stats[\"first_event\"] = grouped[\"_event_time\"].min()\n",
    "        user_stats[\"last_event\"] = grouped[\"_event_time\"].max()\n",
    "        user_stats[\"active_days\"] = (user_stats[\"last_event\"] - user_stats[\"first_event\"]).dt.days + 1\n",
    "        user_stats[\"reviews_per_active_day\"] = user_stats[\"n_reviews\"] / user_stats[\"active_days\"].replace(0, np.nan)\n",
    "\n",
    "    if prob_col is not None and prob_col in df.columns:\n",
    "        user_stats[\"mean_outcome\"] = pd.to_numeric(grouped[prob_col].mean(), errors=\"coerce\")\n",
    "\n",
    "    if interval_col is not None and interval_col in df.columns:\n",
    "        user_stats[\"median_interval\"] = pd.to_numeric(grouped[interval_col].median(), errors=\"coerce\")\n",
    "\n",
    "    print(\"User-level summary statistics:\")\n",
    "    display(user_stats.describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.99]).T)\n",
    "\n",
    "    activity = user_stats[\"n_reviews\"].sort_values(ascending=False)\n",
    "    cumulative_users = np.arange(1, len(activity) + 1) / len(activity)\n",
    "    cumulative_reviews = activity.cumsum() / activity.sum()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    sns.histplot(np.log1p(user_stats[\"n_reviews\"]), bins=60, ax=axes[0], color=\"#BA7430\")\n",
    "    axes[0].set_title(\"User Activity Distribution (log1p scale)\")\n",
    "    axes[0].set_xlabel(\"log1p(n_reviews)\")\n",
    "\n",
    "    axes[1].plot(cumulative_users, cumulative_reviews, color=\"#B36A2B\", linewidth=2)\n",
    "    axes[1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"#8A7E74\", linewidth=1)\n",
    "    axes[1].set_title(\"Concentration Curve of Review Activity\")\n",
    "    axes[1].set_xlabel(\"Cumulative share of users\")\n",
    "    axes[1].set_ylabel(\"Cumulative share of reviews\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if \"mean_outcome\" in user_stats.columns:\n",
    "        scatter_df = user_stats.dropna(subset=[\"mean_outcome\"]).copy()\n",
    "        if len(scatter_df) > 50_000:\n",
    "            scatter_df = scatter_df.sample(50_000, random_state=cfg.random_state)\n",
    "\n",
    "        plt.figure(figsize=(7.5, 5.5))\n",
    "        sns.scatterplot(\n",
    "            data=scatter_df,\n",
    "            x=np.log1p(scatter_df[\"n_reviews\"]),\n",
    "            y=\"mean_outcome\",\n",
    "            alpha=0.15,\n",
    "            s=18,\n",
    "            color=\"#9D5F25\",\n",
    "            linewidth=0,\n",
    "        )\n",
    "        plt.title(\"User Activity vs Mean Outcome\")\n",
    "        plt.xlabel(\"log1p(n_reviews)\")\n",
    "        plt.ylabel(f\"Mean {prob_col}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Level Behavior\n",
    "Item-level diagnostics reveal lexical/content difficulty, exposure concentration, and cross-user consistency. This is critical for understanding curriculum bias and item calibration quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_col = schema[\"item_col\"]\n",
    "user_col = schema[\"user_col\"]\n",
    "prob_col = schema[\"prob_col\"]\n",
    "interval_col = schema[\"interval_col\"]\n",
    "\n",
    "if item_col is None or item_col not in df.columns:\n",
    "    print(\"No item identifier column detected; skipping item-level analysis.\")\n",
    "else:\n",
    "    item_grouped = df.groupby(item_col, dropna=False)\n",
    "    item_stats = pd.DataFrame({\"n_reviews\": item_grouped.size()})\n",
    "\n",
    "    if user_col is not None and user_col in df.columns:\n",
    "        item_stats[\"n_users\"] = item_grouped[user_col].nunique()\n",
    "\n",
    "    if prob_col is not None and prob_col in df.columns:\n",
    "        item_stats[\"mean_outcome\"] = pd.to_numeric(item_grouped[prob_col].mean(), errors=\"coerce\")\n",
    "\n",
    "    if interval_col is not None and interval_col in df.columns:\n",
    "        item_stats[\"median_interval\"] = pd.to_numeric(item_grouped[interval_col].median(), errors=\"coerce\")\n",
    "\n",
    "    print(\"Item-level summary statistics:\")\n",
    "    display(item_stats.describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.99]).T)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(np.log1p(item_stats[\"n_reviews\"]), bins=60, color=\"#B96D2D\")\n",
    "    plt.title(\"Item Exposure Distribution (log1p scale)\")\n",
    "    plt.xlabel(\"log1p(n_reviews)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if \"mean_outcome\" in item_stats.columns:\n",
    "        difficult_items = item_stats[item_stats[\"n_reviews\"] >= cfg.min_group_size].sort_values(\"mean_outcome\").head(20)\n",
    "\n",
    "        if \"lexeme_string\" in df.columns:\n",
    "            label_map = (\n",
    "                df[[item_col, \"lexeme_string\"]]\n",
    "                .dropna()\n",
    "                .drop_duplicates(subset=[item_col])\n",
    "                .set_index(item_col)[\"lexeme_string\"]\n",
    "            )\n",
    "            difficult_items = difficult_items.join(label_map, how=\"left\")\n",
    "\n",
    "        print(f\"Top 20 difficult items (n_reviews >= {cfg.min_group_size}):\")\n",
    "        display(difficult_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations and Notable Interactions\n",
    "The final section quantifies monotonic relationships among numeric variables and evaluates domain-relevant interactions such as spacing interval vs recall probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_analysis = df.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "if numeric_analysis.shape[1] < 2:\n",
    "    print(\"Insufficient numeric columns for correlation analysis.\")\n",
    "else:\n",
    "    corr = numeric_analysis.corr(method=\"spearman\")\n",
    "\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    strongest_pairs = (\n",
    "        upper.stack()\n",
    "        .rename(\"spearman_r\")\n",
    "        .to_frame()\n",
    "        .assign(abs_r=lambda x: x[\"spearman_r\"].abs())\n",
    "        .sort_values(\"abs_r\", ascending=False)\n",
    "    )\n",
    "\n",
    "    print(\"Top correlation pairs by absolute Spearman coefficient:\")\n",
    "    display(strongest_pairs.head(20))\n",
    "\n",
    "    heatmap_cols = numeric_analysis.var().sort_values(ascending=False).head(12).index.tolist()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        numeric_analysis[heatmap_cols].corr(method=\"spearman\"),\n",
    "        cmap=\"RdBu_r\",\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        annot=False,\n",
    "    )\n",
    "    plt.title(\"Spearman Correlation Heatmap (Top-Variance Numeric Features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if schema[\"interval_col\"] is not None and schema[\"prob_col\"] is not None:\n",
    "    interaction = df[[schema[\"interval_col\"], schema[\"prob_col\"]]].copy()\n",
    "    interaction.columns = [\"interval\", \"outcome\"]\n",
    "\n",
    "    interaction[\"interval\"] = pd.to_numeric(interaction[\"interval\"], errors=\"coerce\")\n",
    "    interaction[\"outcome\"] = pd.to_numeric(interaction[\"outcome\"], errors=\"coerce\")\n",
    "    interaction = interaction.dropna()\n",
    "    interaction = interaction[(interaction[\"interval\"] >= 0)]\n",
    "\n",
    "    if not interaction.empty:\n",
    "        upper_cap = interaction[\"interval\"].quantile(0.99)\n",
    "        interaction = interaction[interaction[\"interval\"] <= upper_cap]\n",
    "\n",
    "        n_bins = int(min(12, interaction[\"interval\"].nunique()))\n",
    "        if n_bins >= 3:\n",
    "            interaction[\"interval_bin\"] = pd.qcut(interaction[\"interval\"], q=n_bins, duplicates=\"drop\")\n",
    "            interval_effect = (\n",
    "                interaction.groupby(\"interval_bin\", observed=True)\n",
    "                .agg(n=(\"outcome\", \"size\"), mean_outcome=(\"outcome\", \"mean\"), median_interval=(\"interval\", \"median\"))\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "            print(\"Interval vs outcome (quantile-binned):\")\n",
    "            display(interval_effect)\n",
    "\n",
    "            plt.figure(figsize=(8.5, 5))\n",
    "            sns.lineplot(data=interval_effect, x=\"median_interval\", y=\"mean_outcome\", marker=\"o\", color=\"#A8662A\")\n",
    "            plt.xscale(\"log\")\n",
    "            plt.title(\"Spacing Interval vs Mean Outcome\")\n",
    "            plt.xlabel(\"Median interval (log scale)\")\n",
    "            plt.ylabel(\"Mean outcome\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "if \"history_acc\" in df.columns and schema[\"prob_col\"] is not None:\n",
    "    acc_df = df[[\"history_acc\", schema[\"prob_col\"]]].copy()\n",
    "    acc_df.columns = [\"history_acc\", \"outcome\"]\n",
    "    acc_df[\"history_acc\"] = pd.to_numeric(acc_df[\"history_acc\"], errors=\"coerce\")\n",
    "    acc_df[\"outcome\"] = pd.to_numeric(acc_df[\"outcome\"], errors=\"coerce\")\n",
    "    acc_df = acc_df.dropna()\n",
    "    acc_df = acc_df[(acc_df[\"history_acc\"] >= 0) & (acc_df[\"history_acc\"] <= 1)]\n",
    "\n",
    "    if not acc_df.empty:\n",
    "        acc_df[\"acc_bin\"] = pd.cut(acc_df[\"history_acc\"], bins=np.linspace(0, 1, 11), include_lowest=True)\n",
    "        acc_effect = (\n",
    "            acc_df.groupby(\"acc_bin\", observed=True)\n",
    "            .agg(n=(\"outcome\", \"size\"), mean_outcome=(\"outcome\", \"mean\"))\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(8.5, 5))\n",
    "        sns.lineplot(data=acc_effect, x=\"acc_bin\", y=\"mean_outcome\", marker=\"o\", color=\"#9E5F26\")\n",
    "        plt.title(\"Historical Accuracy vs Current Outcome\")\n",
    "        plt.xlabel(\"History accuracy bin\")\n",
    "        plt.ylabel(\"Mean outcome\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility Notes\n",
    "- All random operations use `cfg.random_state`.\n",
    "- Plot sample size is capped by `cfg.max_rows_for_plots` for stable performance.\n",
    "- All key assumptions (schema inference and time parsing) are explicit in code and easy to audit.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}